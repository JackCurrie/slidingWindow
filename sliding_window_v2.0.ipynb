{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from json...\n",
      "Extra layers of model added\n",
      "Model weights loaded from disk...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 986)               8078298   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 986)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1043)              1029441   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 2088      \n",
      "=================================================================\n",
      "Total params: 29,134,211\n",
      "Trainable params: 11,469,635\n",
      "Non-trainable params: 17,664,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This notebook can be used to analyze a model. ANY model. We are just going to \n",
    "# load this model on up, then run the validation data through it, and get make a nice confusion matrix\n",
    "# from the results :)\n",
    "#\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras import backend as K \n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio as io\n",
    "import cv2 as cv\n",
    "\n",
    "###################################################\n",
    "# You put the file names in here                  #\n",
    "#                                                 #\n",
    "json_path = './models_json/VGG19_transfer[m1]_3.json'\n",
    "weights_path = './weights/VGG19_transfer[m1]_3.h5'\n",
    "\n",
    "\n",
    "# Hardcoded model hyperparameters in for now, may remove\n",
    "#\n",
    "def model_factory(json_path, weight_path):\n",
    "    # Hyperparams\n",
    "    loss = 'categorical_crossentropy'\n",
    "    num_units_first_dense = 986 \n",
    "    dropout_rate = 0.3867433627389078\n",
    "    num_units_second_dense = 1043\n",
    "    lr = 0.006072113068495087\n",
    "    momentum = 0.7963386502886618\n",
    "\n",
    "    model_json = open(json_path, 'r')\n",
    "    loaded_model_json = model_json.read()\n",
    "    model_json.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    print('Model loaded from json...')\n",
    "    \n",
    "    l = model.output\n",
    "    l = Flatten()(l)\n",
    "    l = Dense(num_units_first_dense, activation='relu')(l)\n",
    "    l = Dropout(dropout_rate)(l)\n",
    "    l = Dense(num_units_second_dense, activation='relu')(l)\n",
    "    final = Dense(2, activation='softmax')(l)\n",
    "    model = Model(inputs=model.input, outputs=final)\n",
    "    print('Extra layers of model added')\n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    print('Model weights loaded from disk...')\n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = model_factory(json_path, weights_path)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Image ./test_images/last-close.jpg is 640x360.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full height/width:  90 ,   160\n",
      "full height/width:  180 ,   320\n",
      "full height/width:  270 ,   480\n",
      "full height/width:  360 ,   640\n",
      "full height/width:  540 ,   960\n",
      "full height/width:  720 ,   1280\n",
      "full height/width:  1440 ,   2560\n",
      "1168\n"
     ]
    }
   ],
   "source": [
    "# THIS WILL INPUT A SINGLE IMAGE WHICH WE WILL BE USING TO TEST OUR SLIDING WINDOW CAPABILITIEZZZ \n",
    "#\n",
    "imageName = './test_images/last-close.jpg'\n",
    "image = cv.imread(imageName)\n",
    "imageHeight, imageWidth, imageChannels = image.shape\n",
    "\n",
    "\n",
    "#Parameters to play around with\n",
    "window_size = 128     #REMEBER TO CHANGE THIS TO 128!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "stride_factor = .5 # Percent of window size to use as convStride\n",
    "\n",
    "\n",
    "class boxResult:\n",
    "    x=0\n",
    "    y=0\n",
    "    height=0\n",
    "    width=0\n",
    "    class_pred=0\n",
    "    confidence=0.0\n",
    "\n",
    "    \n",
    "    \n",
    "# Input: model to use, image to use, top-left-corner coordinates tuple (x, y), and\n",
    "#        currentScale\n",
    "# Output: Single boxResult with dimensions scaled back to the un-scaled\n",
    "#\n",
    "def modelPredict(model, predictionImage, tlc, currentScale):\n",
    "    img_height = predictionImage.shape[0] \n",
    "    img_width = predictionImage.shape[1] \n",
    "    \n",
    "    # !!! I AM NOT SURE IF THIS IS SUFFICIENT/CORRECT PRE-PROCESSING\n",
    "    #      - Also, if we come back and do some extra aspect ratio stuff!!! This will need to be changed \n",
    "    #\n",
    "    predictionImage = np.divide(predictionImage, 255)\n",
    "    result = model.predict( np.array([predictionImage,]))\n",
    "    confidence = np.max(result[0]) \n",
    "    class_index = np.argmax(result[0]) \n",
    "    \n",
    "    \n",
    "    temp = boxResult()\n",
    "    temp.x = int(tlc[0] / currentScale)\n",
    "    temp.y = int(tlc[1] / currentScale)\n",
    "    temp.height = int(img_height / currentScale)\n",
    "    temp.width = int(img_width / currentScale)\n",
    "    temp.confidence = confidence \n",
    "    \n",
    "    if class_index == 0:\n",
    "        temp.class_pred = 'car'\n",
    "    else:\n",
    "        temp.class_pred = 'non-car'\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "#Image info\n",
    "display(\"Image \" + str(imageName) + \" is \" + str(imageWidth) + \"x\" + str(imageHeight) + \".\")\n",
    "\n",
    "# !!! Revisit these scales \n",
    "scales = [.25, .5, .75, 1, 1.5, 2, 4]\n",
    "# scales = [1] # !!! TEMP!!!!!\n",
    "\n",
    "\n",
    "img_pyramid = []\n",
    "\n",
    "for scale in scales:\n",
    "    scaled_img = cv.resize(image, None, fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "    img_pyramid.append({'scale': scale, 'img': scaled_img})\n",
    "\n",
    "# Iterate through scaled_img\n",
    "#    Iterate through total number of vertical window strides\n",
    "#       Iterate through total number of horizontal window strides\n",
    "#          Append prediction with MAPPED coordinates to list  \n",
    "#\n",
    "predictions = []\n",
    "for pyr_layer in img_pyramid:\n",
    "    img_height = pyr_layer['img'].shape[0]\n",
    "    img_width =  pyr_layer['img'].shape[1]\n",
    "\n",
    "    tlc_y = 0\n",
    "    tlc_x = 0\n",
    "    print('full height/width: ', img_height, ',  ', img_width)\n",
    "    \n",
    "    # !!! Current methodology leaves SLIGHT gaps at bottom of image, revamp later on\n",
    "    #     with better one\n",
    "    if img_height > window_size and img_width > window_size: \n",
    "        for tlc_y in range(0, (img_height - window_size), int(np.round(window_size * stride_factor))):\n",
    "            for tlc_x in range(0, (img_width - window_size), int(np.round(window_size * stride_factor))):\n",
    "                window_img = pyr_layer['img'][tlc_y:(tlc_y + window_size), tlc_x:(tlc_x + window_size), :]\n",
    "                predictions.append(modelPredict(model, window_img, (tlc_x, tlc_y), pyr_layer['scale']))  \n",
    "    \n",
    "            # Make a prediction using the farthest-right-possible x value to cover gap\n",
    "            window_img = pyr_layer['img'][tlc_y:(tlc_y + window_size), (img_width - window_size):img_width, :]\n",
    "            predictions.append(modelPredict(model, window_img, (img_width - window_size, tlc_y), pyr_layer['scale'])) \n",
    "            \n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suppress all\n",
    "#\n",
    "#\n",
    "#\n",
    "def nonMaxSuppression(predictions, conf_thresh, overlap_thresh):\n",
    "    filtered_preds = [pred for pred in predictions if pred.class_pred == 'car' and pred.confidence > conf_thresh]\n",
    "    \n",
    "    if not filtered_preds:\n",
    "        return []\n",
    "    \n",
    "    pick = []\n",
    "\n",
    "    # Here we need to get the coordinates of the corners (x1, y1) and (x2, y2) in their own respective arrays\n",
    "    x1 = np.array([pred.x for pred in filtered_preds])\n",
    "    y1 = np.array([pred.y for pred in filtered_preds])\n",
    "    x2 = np.array([pred.x + pred.width for pred in filtered_preds])\n",
    "    y2 = np.array([pred.y + pred.height for pred in filtered_preds])\n",
    "    \n",
    "    \n",
    "    areas = (x2 - x1) * (y2 - y1) \n",
    "    indices = np.argsort(y2)\n",
    "    \n",
    "    # Keep looping while some indices still remain in the indices list\n",
    "    while len(indices) > 0:\n",
    "        last = len(indices) - 1\n",
    "        index = indices[last] \n",
    "        pick.append(indices[-1])\n",
    "    \n",
    "        # Find largest (x, y) coordinates for the start of the bounding box and \n",
    "        # smallest (x, y) coordinates for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[index], x1[indices[:last]])\n",
    "        yy1 = np.maximum(y1[index], y1[indices[:last]])\n",
    "        xx2 = np.minimum(x2[index], x2[indices[:last]])\n",
    "        yy2 = np.minimum(y2[index], y2[indices[:last]])\n",
    "    \n",
    "        # Tutorial mentions something about  a  \"+ 1\", but I don't really get it\n",
    "        w = np.maximum(0, xx2 - xx1)\n",
    "        h = np.maximum(0, yy2 - yy1)\n",
    "    \n",
    "        overlap = (w * h) / areas[indices[:last]]\n",
    "        indices = np.delete(indices, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))\n",
    "    \n",
    "    \n",
    "    # print(predictions)\n",
    "    return [pred for i, pred in enumerate(filtered_preds) if i in pick]\n",
    "    \n",
    "    \n",
    "# I have no idea at all what a good overlap threshhold would be\n",
    "#\n",
    "new_preds = nonMaxSuppression(predictions, .8, .5) \n",
    "print(len(new_preds))    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This will be a great animation for our presentation! Come back to this\n",
    "#\n",
    "#\n",
    "storageImage = image \n",
    "displayImage = image \n",
    "prevHeight = 0\n",
    "lineColor = (255,0,0)\n",
    "lineWidth = 2\n",
    "\n",
    "\n",
    "just_cars = [pred for pred in predictions if pred.class_pred == 'car']\n",
    "print(len(just_cars))\n",
    "\n",
    "\n",
    "displayImage = image\n",
    "\n",
    "for box in new_preds:\n",
    "    cv.rectangle(displayImage,(box.x,box.y),(box.x+box.width,box.y+box.height),lineColor,lineWidth)\n",
    "    cv.imshow('Windows',displayImage)\n",
    "    cv.waitKey(500)\n",
    "    displayImage = storageImage.copy()\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
